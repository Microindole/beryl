// lencyc/driver/test_entry.lcy
// 自举版 Lency 编译器的词法与语法测试入口

import std.core
import std.fs
import std.convert
import lencyc.syntax.lexer
import lencyc.syntax.parser

int main() {
    print("Running Lency Self-hosted Compiler Lexer/Parser Tests...\n")
    
    // 读取自身的 Token 定义文件作为测试输入
    var path = "lencyc/syntax/token.lcy"
    print("Reading test file: " + path + "\n")
    
    var source_res = read_to_string(path)
    if source_res.is_err() {
        print("Failed to read file: " + path + "\n")
        return 1
    }
    var source = source_res.unwrap()
    
    print("Step 1: Lexing test...\n")
    var lexer = make_lexer(source)
    var count = 0
    while true {
        var token = lexer.scan_token()
        count = count + 1
        if token.kind == 0 { // T_EOF
            break
        }
        if token.kind == 1 { // T_ERROR
            print("Lexer error at line " + int_to_string(token.line) + "\n")
            return 1
        }
    }
    print("Successfully lexed " + int_to_string(count) + " tokens.\n")
    
    print("Step 2: Parsing test...\n")
    var simple_source = "var i = 0\nwhile i < 10 && i != 5 {\n    i = i + 1\n}" 
    var parser = make_parser(simple_source)
    var statements = parser.parse()
    
    if parser.has_error {
        print("Parsing failed!\n")
        return 1
    }
    
    print("Successfully parsed " + int_to_string(statements.len()) + " statements.\n")
    print("Tests completed successfully.\n")
    return 0
}
